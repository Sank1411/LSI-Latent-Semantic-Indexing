{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Indexing (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import heapq \n",
    "import math\n",
    "from collections import defaultdic\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(filename):\n",
    "    unformatted_words = []\n",
    "    with open(filename,'r') as file:      \n",
    "        for line in file:     \n",
    "            for word in line.split():   \n",
    "                unformatted_words.append(word)\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~1234567890'''\n",
    "    dict_list=[]\n",
    "    for word in unformatted_words:\n",
    "        no_punct = \"\"\n",
    "        for character in word:\n",
    "            if character not in punctuations:\n",
    "                no_punct = no_punct + character\n",
    "        if no_punct != \"\":\n",
    "            dict_list.append(no_punct.lower())\n",
    "    key = []\n",
    "    for word in dict_list:\n",
    "        if word not in key:\n",
    "            key.append(word)\n",
    "    freq = []\n",
    "    for i in range(len(key)):\n",
    "        freq.append(dict_list.count(key[i]))\n",
    "    dictionary=[]\n",
    "    for i in range(len(key)):\n",
    "        dictionary.append((key[i],freq[i]))\n",
    "    dictionary.sort(key = lambda x: x[0])\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(words):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~1234567890'''\n",
    "    dict_list=[]\n",
    "    for word in words:\n",
    "        no_punct = \"\"\n",
    "        for char in word:\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "        if no_punct != \"\":\n",
    "            dict_list.append(no_punct.lower())\n",
    "    key = []\n",
    "    for word in dict_list:\n",
    "        if word not in key:\n",
    "            key.append(word)\n",
    "    freq = []\n",
    "    for i in range(len(key)):\n",
    "        freq.append(dict_list.count(key[i]))\n",
    "    return key,freq\n",
    "def get_vector(query_words,query_term_freq,final_words):\n",
    "    query_vector=[]\n",
    "    for word in final_words:\n",
    "        if word not in query_words:\n",
    "            query_vector.append(0)\n",
    "        else:\n",
    "            for i in range(len(query_words)):\n",
    "                if word == query_words[i]:\n",
    "                    query_vector.append(query_term_freq[i])\n",
    "    query_vector=np.array(query_vector)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_document_matrix(doc_list):\n",
    "    n = len(doc_list)\n",
    "    final_words=[]\n",
    "    for i in range(n):\n",
    "        for word,freq in doc_list[i]:\n",
    "            if word not in final_words:\n",
    "                final_words.append(word)\n",
    "    final_words.sort()\n",
    "    matrix=[]\n",
    "    for word in final_words:\n",
    "        temp=[]\n",
    "        for i in range(n):\n",
    "            present = False\n",
    "            for doc_word,term_freq in doc_list[i]:\n",
    "                if doc_word==word:\n",
    "                    present = True\n",
    "                    temp.append(term_freq)\n",
    "            if present == False:\n",
    "                temp.append(0)\n",
    "        matrix.append(temp)\n",
    "    return final_words,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'according', 'act', 'action', 'affects', 'after', 'against', 'also', 'and', 'are', 'as', 'be', 'been', 'being', 'but', 'by', 'can', 'cannot', 'causing', 'characteristic', 'classic', 'classical', 'collapse', 'copenhagen', 'creates', 'darwinian', 'darwinism', 'definite', 'determine', 'distribution', 'do', 'doubleslit', 'due', 'emergence', 'environment', 'eraser', 'establishes', 'experiment', 'explain', 'favor', 'feature', 'fringe', 'fringes', 'from', 'function', 'generally', 'given', 'has', 'have', 'immediately', 'in', 'induced', 'interacting', 'interfere', 'interference', 'interpretation', 'is', 'it', 'itself', 'known', 'later', 'level', 'many', 'marked', 'material', 'meant', 'measured', 'measurement', 'measurements', 'mechanics', 'microscopic', 'natural', 'not', 'objects', 'of', 'on', 'one', 'only', 'passed', 'patterns', 'photon', 'photons', 'pointer', 'possible', 'predict', 'prior', 'probabilities', 'probability', 'process', 'produce', 'properties', 'quantum', 'reduce', 'results', 'reveal', 'seen', 'selected', 'selection', 'set', 'situations', 'slit', 'slits', 'stable', 'state', 'states', 'stream', 'system', 'taken', 'that', 'the', 'then', 'theory', 'this', 'thomas', 'through', 'to', 'unmarked', 'values', 'variation', 'wave', 'way', 'when', 'where', 'which', 'will', 'with', 'world', 'young', 'youngs']\n",
      "[[3 6 2]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 3 1]\n",
      " [1 0 0]\n",
      " [1 0 1]\n",
      " [0 2 0]\n",
      " [0 3 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [0 2 0]\n",
      " [0 0 1]\n",
      " [0 2 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 5 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 2 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 5 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 2 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 3 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 3 1]\n",
      " [0 2 0]\n",
      " [0 3 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 4 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 2]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 2 1]\n",
      " [0 0 1]\n",
      " [3 5 4]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 2]\n",
      " [0 2 0]\n",
      " [0 1 0]\n",
      " [0 5 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 2]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 1]\n",
      " [4 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [0 4 0]\n",
      " [6 6 7]\n",
      " [0 2 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 2 0]\n",
      " [2 2 4]\n",
      " [0 2 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 2 0]\n",
      " [1 0 0]\n",
      " [0 3 0]\n",
      " [0 3 0]\n",
      " [1 3 0]\n",
      " [2 0 0]\n",
      " [0 1 0]\n",
      " [0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "dict1 = extract_from_file(\"d1.txt\")\n",
    "dict2 = extract_from_file(\"d2.txt\")\n",
    "dict3 = extract_from_file(\"d3.txt\")\n",
    "doc_list=[dict1,dict2,dict3]\n",
    "final_words,matrix = get_term_document_matrix(doc_list)\n",
    "matrix = np.array(matrix)\n",
    "print(final_words)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, V_t = np.linalg.svd(matrix, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: [[-0.33302576  0.00670728 -0.13927323]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.14368376 -0.06325438  0.10332297]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.03272136  0.10501172 -0.02733681]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.12618181 -0.12386076  0.01535339]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.05956255  0.01931946  0.09308738]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.21030302 -0.20643459  0.02558898]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.21030302 -0.20643459  0.02558898]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.09934063 -0.03816849 -0.1050708 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.12618181 -0.12386076  0.01535339]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.15890317 -0.01884903 -0.01198342]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.12618181 -0.12386076  0.01535339]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.16824242 -0.16514767  0.02047118]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.03500388  0.12121276  0.17593917]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.10162315 -0.02196746  0.09820517]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.32596904  0.16920695  0.03154814]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.03500388  0.12121276  0.17593917]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.21030302 -0.20643459  0.02558898]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.0502233   0.1656181   0.06063278]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.12044022  0.19694083 -0.36813818]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.03272136  0.10501172 -0.02733681]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.16824242 -0.16514767  0.02047118]\n",
      " [-0.46619372  0.4429552  -0.04534449]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.05956255  0.01931946  0.09308738]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.18456781  0.24866236  0.13150114]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.01750194  0.06060638  0.08796958]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.08412121 -0.08257384  0.01023559]\n",
      " [-0.01521942  0.04440534 -0.11530639]\n",
      " [-0.12618181 -0.12386076  0.01535339]\n",
      " [-0.12618181 -0.12386076  0.01535339]\n",
      " [-0.14140123 -0.07945541 -0.099953  ]\n",
      " [-0.03043883  0.08881069 -0.23061278]\n",
      " [-0.0420606  -0.04128692  0.0051178 ]\n",
      " [-0.08412121 -0.08257384  0.01023559]]\n",
      "\n",
      "Sigma: [20.81958884 11.66457236  6.89075265]\n",
      "\n",
      "V: [[-0.31686201 -0.87568449 -0.36438323]\n",
      " [ 0.51796934 -0.48159425  0.70694749]\n",
      " [-0.79454782  0.03526546  0.60617664]]\n"
     ]
    }
   ],
   "source": [
    "print(\"U:\",U)\n",
    "print(\"\\nSigma:\",Sigma)\n",
    "print(\"\\nV:\",V_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_new = np.delete(U, -1, axis=1)\n",
    "V_t_new = np.delete(V_t, -1,axis=0)\n",
    "Sigma_new = np.delete(Sigma,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: [[-0.33302576  0.00670728]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.14368376 -0.06325438]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.03272136  0.10501172]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.12618181 -0.12386076]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.05956255  0.01931946]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.21030302 -0.20643459]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.21030302 -0.20643459]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.09934063 -0.03816849]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.12618181 -0.12386076]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.15890317 -0.01884903]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.12618181 -0.12386076]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.16824242 -0.16514767]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.03500388  0.12121276]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.10162315 -0.02196746]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.32596904  0.16920695]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.03500388  0.12121276]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.21030302 -0.20643459]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.0502233   0.1656181 ]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.12044022  0.19694083]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.03272136  0.10501172]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.16824242 -0.16514767]\n",
      " [-0.46619372  0.4429552 ]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.05956255  0.01931946]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.18456781  0.24866236]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.01750194  0.06060638]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.08412121 -0.08257384]\n",
      " [-0.01521942  0.04440534]\n",
      " [-0.12618181 -0.12386076]\n",
      " [-0.12618181 -0.12386076]\n",
      " [-0.14140123 -0.07945541]\n",
      " [-0.03043883  0.08881069]\n",
      " [-0.0420606  -0.04128692]\n",
      " [-0.08412121 -0.08257384]]\n",
      "\n",
      "Sigma: [20.81958884 11.66457236]\n",
      "\n",
      "V: [[-0.31686201 -0.87568449 -0.36438323]\n",
      " [ 0.51796934 -0.48159425  0.70694749]]\n"
     ]
    }
   ],
   "source": [
    "print(\"U:\",U_new)\n",
    "print(\"\\nSigma:\",Sigma_new)\n",
    "print(\"\\nV:\",V_t_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query :Copenhagen interpretation and quantum darwinism.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter query :\").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#get the query terms and their frequencies\n",
    "query_words,query_term_freq = unpack_document(query)\n",
    "#convert query into vector\n",
    "query_vector = get_vector(query_words,query_term_freq,final_words)\n",
    "print(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99206361 -0.62148698]\n"
     ]
    }
   ],
   "source": [
    "#convert query into new reduced 2-dimensional query\n",
    "new_query = np.matmul(query_vector.transpose(),U_new)\n",
    "new_query = np.matmul(new_query,np.linalg.inv(np.diag(np.diag(V_t_new))))\n",
    "print(new_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack terms from documents of corpus\n",
    "words = []\n",
    "for dict_ in doc_list:\n",
    "    words.append([a_tuple[0] for a_tuple in dict_])\n",
    "\n",
    "#calculate terms and term_frequencies for documents in a corpus\n",
    "doc_words,doc_tf=[],[]\n",
    "for word_ in words:\n",
    "    temp1,temp2=unpack_document(word_)\n",
    "    doc_words.append(temp1)\n",
    "    doc_tf.append(temp2)\n",
    "\n",
    "#convert documents into vectors\n",
    "doc_vectors=[]\n",
    "for i in range(len(doc_words)):\n",
    "    doc_vectors.append(get_vector(doc_words[i],doc_tf[i],final_words))\n",
    "\n",
    "#reducing the document vector dimension\n",
    "reduced_doc_vectors=[]\n",
    "for doc_vector in doc_vectors:\n",
    "    reduced_doc_vector = np.matmul(doc_vector.transpose(),U_new)\n",
    "    reduced_doc_vector = np.matmul(reduced_doc_vector,np.linalg.inv(np.diag(np.diag(V_t_new))))\n",
    "    reduced_doc_vectors.append(reduced_doc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 7.4848079 , -5.28866539]), array([18.47348676,  5.62827557]), array([ 8.85015934, -8.1399438 ])]\n"
     ]
    }
   ],
   "source": [
    "print(reduced_doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate cosine score\n",
    "scores = []\n",
    "for i in range(len(reduced_doc_vectors)):\n",
    "    doc_score = cosine_similarity([new_query], [reduced_doc_vectors[i]])\n",
    "    scores.append(doc_score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_documents=[]\n",
    "for i in range(len(doc_list)):\n",
    "    ranked_documents.append((\"document-\"+str(i+1),scores[i]))\n",
    "ranked_documents.sort(key = lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('document-1', 0.998461090077326), ('document-3', 0.983124624951171), ('document-2', 0.6559307714729127)]\n"
     ]
    }
   ],
   "source": [
    "print(ranked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
